{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('aiffel': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8182dd0ad4173cdddc5298b982923877be00ee4d2f569af5d6459bf4e939e93c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ëª¨ë“ˆ\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì— í•„ìš”í•œ í•¨ìˆ˜ë“¤ ì‘ì„± <br><br>\n",
    "\n",
    "- Positional Encoding Layer (í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´) <br>\n",
    "- Scaled Dot-product Attention (í”„ë¡œë•íŠ¸ ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜) <br>\n",
    "- Multi-head Attention (ë©€í‹°-í—¤ë“œ ì–´í…ì…˜) <br>\n",
    "- Padding Mask (íŒ¨ë”© ë§ˆìŠ¤í¬) <br>\n",
    "- Look-ahead Mask (ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬) <br>\n",
    "- Encoder (ì¸ì½”ë”) <br>\n",
    "- Decoder (ë””ì½”ë”) <br>\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ì±—ë´‡ ë³‘ë ¬ ë°ì´í„° ì½ì–´ì˜¤ê¸° <br><br>\n",
    "\n",
    "__Chatbot_data_for_Korean v1.0 ë°ì´í„°ì…‹__ <br>\n",
    "- í•©ìŠµìš© ì§ˆë¬¸/ë‹µë©´ ìŒ 11,823ê°œ <br>\n",
    "- ì¼ìƒë‹¤ë°˜ì‚¬ 0, ì´ë³„(ë¶€ì •) 1, ì‚¬ë‘(ê¸ì •) 2 ë¡œ ë ˆì´ë¸”ë§ <br><br>\n",
    "\n",
    "- 11,823ê°œ ì§ˆë¬¸/ë‹µë³€ ìŒì„ ì¶”ì¶œ <br>\n",
    "- ë¬¸ì¥ì—ì„œ ë‹¨ì–´ì™€ êµ¬ë‘ì  ì‚¬ì´ì— ê³µë°± ì¶”ê°€ <br>\n",
    "- ì•ŒíŒŒë²³ê³¼ ! ? , . ì´ 4ê°œì˜ êµ¬ë‘ì ì„ ì œì™¸í•œ ë‹¤ë¥¸ íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ ì œê±°\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì „ì²´ ìƒ˜í”Œìˆ˜ : 11823\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "data = pd.read_csv(os.getenv(\"HOME\") + \"/aiffel/transformer_chatbot/data/ChatbotData.csv\")\n",
    "\n",
    "print('ì „ì²´ ìƒ˜í”Œìˆ˜ :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         Q                   A  label\n",
       "0                   12ì‹œ ë•¡!          í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1              1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´           ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2             3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤         ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3          3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤         ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4                  PPL ì‹¬í•˜ë„¤          ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0\n",
       "5                SDì¹´ë“œ ë§ê°€ì¡Œì–´  ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.      0\n",
       "6                  SDì¹´ë“œ ì•ˆë¼  ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.      0\n",
       "7           SNS ë§íŒ” ì™œ ì•ˆí•˜ì§€ã… ã…     ì˜ ëª¨ë¥´ê³  ìˆì„ ìˆ˜ë„ ìˆì–´ìš”.      0\n",
       "8  SNS ì‹œê°„ë‚­ë¹„ì¸ ê±° ì•„ëŠ”ë° ë§¤ì¼ í•˜ëŠ” ì¤‘       ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.      0\n",
       "9        SNS ì‹œê°„ë‚­ë¹„ì¸ë° ìê¾¸ ë³´ê²Œë¨       ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q</th>\n      <th>A</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12ì‹œ ë•¡!</td>\n      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PPL ì‹¬í•˜ë„¤</td>\n      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SDì¹´ë“œ ë§ê°€ì¡Œì–´</td>\n      <td>ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SDì¹´ë“œ ì•ˆë¼</td>\n      <td>ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SNS ë§íŒ” ì™œ ì•ˆí•˜ì§€ã… ã… </td>\n      <td>ì˜ ëª¨ë¥´ê³  ìˆì„ ìˆ˜ë„ ìˆì–´ìš”.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SNS ì‹œê°„ë‚­ë¹„ì¸ ê±° ì•„ëŠ”ë° ë§¤ì¼ í•˜ëŠ” ì¤‘</td>\n      <td>ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SNS ì‹œê°„ë‚­ë¹„ì¸ë° ìê¾¸ ë³´ê²Œë¨</td>\n      <td>ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "# ë°ì´í„° ìƒ˜í”Œ í™•ì¸\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ë°ì´í„°ì…‹ ê°€ê³µì„ ìœ„í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜ <br>\n",
    "\n",
    "__ì •ê·œ í‘œí˜„ì‹(Regular Expression)__ì„ ì‚¬ìš©í•˜ì—¬ __êµ¬ë‘ì (punctuation)__ì„ ì œê±°í•˜ì—¬ <br>\n",
    "ë‹¨ì–´ë¥¼ __í† í¬ë‚˜ì´ì§•(tokenizing)__í•˜ëŠ” ì¼ì— ë°©í•´ê°€ ë˜ì§€ ì•Šë„ë¡ ì •ì œí•˜ëŠ” ê²ƒì„ ëª©í‘œ <br><br>\n",
    "\n",
    "ë‹¨ì–´ë¥¼ í† í¬ë‚˜ì´ì§• í•˜ëŠ” ê³¼ì •ì—ì„œ êµ¬ë‘ì ê³¼ ë¶™ì–´ìˆë˜ ë‹¨ì–´ë“¤ì„ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ <br>\n",
    "ì œê±°í•  ëŒ€ìƒë“¤ì„ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # êµ¬ë‘ì ë„ ë¬¸ì¥ë‚´ ë‹¨ì–´ìœ„ì¹˜ì— ë”°ë¼ ìœ ì˜ë¯¸ í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ êµ¬ë‘ì  ì œê±°ëŠ” í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
    "  # ë‹¨ì–´ì™€ êµ¬ë‘ì (punctuation) ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "  # ì˜ˆë¥¼ ë“¤ì–´ì„œ \"I am a student.\" => \"I am a student .\"ì™€ ê°™ì´\n",
    "  # sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  # sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (ã„±-ã…, ê°€-í£, a-z, A-Z, \".\", \"?\", \"!\", \",\")ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ ê³µë°±ì¸ ' 'ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "  sentence = re.sub(r\"[^ã„±-ã…ê°€-í£a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ë•ë°°ì…ë‹ˆë‹¤.\në°˜ê°‘ìŠµë‹ˆë‹¤, ì¢‹ì€ ë‚ ì”¨ë„¤ìš”!!!\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ í™•ì¸\n",
    "\n",
    "temp_text = 'ì•ˆë…•í•˜ì„¸ìš”, ê¹€ë•ë°°ì…ë‹ˆë‹¤.'\n",
    "temp_summary = 'ë°˜ê°‘ìŠµë‹ˆë‹¤, ì¢‹ì€ ë‚ ì”¨ë„¤ìš”!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ì§ˆë¬¸ê³¼ ë‹µë³€ ê°ê°ì— ëŒ€í•´ ì „ì²˜ë¦¬\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ìŒ ê°ê°ì— ëŒ€í•´ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì „ì²˜ë¦¬\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ì‹œ ë•¡!', 'ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´', 'ë°• ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', 'ë°• ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', 'ppl ì‹¬í•˜ë„¤']"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "# 'Q' ì¹¼ëŸ¼ì˜ ë°ì´í„° ì „ì²˜ë¦¬ (ë¶ˆìš©ì–´ ì œê±°)\n",
    "\n",
    "inputs = []\n",
    "\n",
    "# 'Q' ì¹¼ëŸ¼ ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì „ì²˜ë¦¬\n",
    "for s in data['Q']:\n",
    "    inputs.append(preprocess_sentence(s))\n",
    "\n",
    "# ì „ì²˜ë¦¬ í›„ ì¶œë ¥ í™•ì¸\n",
    "inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.', 'ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .', 'ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .']"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "# 'A' ì¹¼ëŸ¼ì˜ ë°ì´í„° ì „ì²˜ë¦¬ (ë¶ˆìš©ì–´ ì œê±°)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "# 'A' ì¹¼ëŸ¼ ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì „ì²˜ë¦¬\n",
    "for s in data['A']:\n",
    "    outputs.append(preprocess_sentence(s))\n",
    "\n",
    "# ì „ì²˜ë¦¬ í›„ ì¶œë ¥ í™•ì¸\n",
    "outputs[:5]"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "#### ë°ì´í„°ì˜ ìƒ˜í”Œ ìˆ˜ í™•ì¸ <br><br>\n",
    "\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ë³‘ë ¬ì ìœ¼ë¡œ êµ¬ì„±ë˜ëŠ” ë°ì´í„°ì…‹ì´ë¯€ë¡œ ë‘ ìƒ˜í”Œ ìˆ˜ëŠ” ì •í™•í•˜ê²Œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. <br><br>\n",
    "\n",
    "ì„ì˜ë¡œ 22ë²ˆì§¸ ìƒ˜í”Œ(ì¸ë±ìŠ¤ ìƒìœ¼ë¡œëŠ” 21ë²ˆ ìƒ˜í”Œ)ì„ ì¶œë ¥í•´ì„œ <br>\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë³‘ë ¬ì ìœ¼ë¡œ ì˜ ì €ì¥ì€ ë˜ì—ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì „ì²˜ë¦¬ í•¨ìˆ˜ì—ì„œ ì˜ë„í–ˆë˜ ì „ì²˜ë¦¬ê°€ ì§„í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜ : 11823\nì „ì²´ ìƒ˜í”Œ ìˆ˜ : 11823\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ í›„ ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸\n",
    "\n",
    "print('ì „ì²´ ìƒ˜í”Œ ìˆ˜ :', len(inputs))\n",
    "print('ì „ì²´ ìƒ˜í”Œ ìˆ˜ :', len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: ê°€ìŠ¤ë¹„ ì¥ë‚œ ì•„ë‹˜\nì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: ë‹¤ìŒ ë‹¬ì—ëŠ” ë” ì ˆì•½í•´ë´ìš”.\n"
     ]
    }
   ],
   "source": [
    "# 22ë²ˆì§¸ ìƒ˜í”Œ ì¶œë ¥í•´ì„œ ì§ˆë¬¸/ë‹µë³€ ë³‘ë ¬ì €ì¥, ì „ì²˜ë¦¬ í™•ì¸\n",
    "\n",
    "print('ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: {}'.format(inputs[21]))\n",
    "print('ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: {}'.format(outputs[21]))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ë³‘ë ¬ ë°ì´í„° ì „ì²˜ë¦¬ <br><br>\n",
    "\n",
    "1. ê° ë¬¸ì¥ì„ í† í°í™”í•˜ê³ , ê° ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ëì„ ë‚˜íƒ€ë‚´ëŠ” START_TOKEN ë° END_TOKENì„ ì¶”ê°€ <br><br>\n",
    "\n",
    "2. TensorFlow Datasets SubwordTextEncoderë¥¼ í† í¬ë‚˜ì´ì €ë¡œ ì‚¬ìš© <br>\n",
    "    - ë‹¨ì–´ë³´ë‹¤ ë” ì‘ì€ ë‹¨ìœ„ì¸ Subwordë¥¼ ê¸°ì¤€ìœ¼ë¡œ í† í¬ë‚˜ì´ì§• <br>\n",
    "    - ê° í† í°ì„ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ì¸ì½”ë”© <br><br>\n",
    "\n",
    "3. ìµœëŒ€ ê¸¸ì´ MAX_LENGTHì¸ 40ì„ ë„˜ëŠ” ë¬¸ì¥ë“¤ì€ í•„í„°ë§ <br><br>\n",
    "\n",
    "4. MAX_LENGTHë³´ë‹¤ ê¸¸ì´ê°€ ì§§ì€ ë¬¸ì¥ë“¤ì€ 40ì— ë§ë„ë¡ íŒ¨ë”©\n",
    "\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 1. ë‹¨ì–´ì¥(Vocabulary) ë§Œë“¤ê¸° <br><br>\n",
    "\n",
    "ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬í•˜ê¸° ìœ„í•´ì„œ ë‹¨ì–´ì¥(Vocabulary) ìƒì„± <br>\n",
    "ë‹¨ì–´ì¥ì„ ë§Œë“¤ ë•ŒëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€ ë°ì´í„°ì…‹ì„ ëª¨ë‘ ì‚¬ìš© ! <br><br>\n",
    "\n",
    "tensorflow_datasets ì—ì„œ <br>\n",
    "tensorflow_datasets.deprecated.text.SubwordTextEncoder.build_from_corpus ì´ìš©\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì‚´ì§ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”. ìŠ¤íŠ¸ë ˆì¹­ í•œ ë²ˆ í•´ë³¼ê¹Œìš”? ğŸ‘\n"
     ]
    }
   ],
   "source": [
    "print(\"ì‚´ì§ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”. ìŠ¤íŠ¸ë ˆì¹­ í•œ ë²ˆ í•´ë³¼ê¹Œìš”? ğŸ‘\")\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ë‹µë³€ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ Vocabulary ìƒì„±. (Tensorflow 2.2.0 ì´í•˜)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(inputs + outputs, target_vocab_size=2**13)\n",
    "\n",
    "# (ì£¼ì˜) Tensorflow 2.3.0 ì´ìƒì˜ ë²„ì „ì—ì„œëŠ” ì•„ë˜ ì£¼ì„ì˜ ì½”ë“œë¥¼ ëŒ€ì‹  ì‹¤í–‰í•´ ì£¼ì„¸ìš”. \n",
    "#tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(inputs + outputs, target_vocab_size=2**13)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "#### ì‹œì‘/ì¢…ë£Œ í† í°ë„ ë‹¨ì–´ì¥ì— ì¶”ê°€ <br>\n",
    "ë””ì½”ë”ì˜ ë¬¸ì¥ ìƒì„± ê³¼ì •ì—ì„œ ì‚¬ìš©í•  'ì‹œì‘ í† í°'ê³¼ 'ì¢…ë£Œ í† í°'ì— ëŒ€í•´ì„œë„ ì„ì˜ë¡œ ë‹¨ì–´ì¥ì— ì¶”ê°€í•˜ì—¬ì„œ ì •ìˆ˜ë¥¼ ë¶€ì—¬í•´ ì¤ë‹ˆë‹¤. <br>\n",
    "ì´ë¯¸ ìƒì„±ëœ ë‹¨ì–´ì¥ì˜ ë²ˆí˜¸ì™€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ê°ê° ë‹¨ì–´ì¥ì˜ í¬ê¸°ì™€ ê·¸ë³´ë‹¤ 1ì´ í° ìˆ˜ë¥¼ ë²ˆí˜¸ë¡œ ë¶€ì—¬í•˜ë©´ ë©ë‹ˆë‹¤. \n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì— ê³ ìœ í•œ ì •ìˆ˜ë¥¼ ë¶€ì—¬\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "START_TOKENì˜ ë²ˆí˜¸ : [8133]\nEND_TOKENì˜ ë²ˆí˜¸ : [8134]\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì‘ í† í°, ì¢…ë£Œ í† í°ì— ë¶€ì—¬ëœ ì •ìˆ˜ í™•ì¸\n",
    "\n",
    "print('START_TOKENì˜ ë²ˆí˜¸ :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKENì˜ ë²ˆí˜¸ :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "í˜„ì¬ ë‹¨ì–´ì¥ì˜ í¬ê¸°ê°€ 8,331(0ë²ˆë¶€í„° 8,330ë²ˆ)ì´ë¼ëŠ” ì˜ë¯¸ ! <br>\n",
    "ë‘ ê°œì˜ í† í°ì„ ì¶”ê°€í•´ì£¼ì—ˆê¸° ë•Œë¬¸ì— ë‹¨ì–´ì¥ì˜ í¬ê¸°ë„ +2ì„ì„ ëª…ì‹œ\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8135\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ê³ ë ¤í•˜ì—¬ +2ë¥¼ í•˜ì—¬ ë‹¨ì–´ì¥ì˜ í¬ê¸°ë¥¼ ì‚°ì •\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 2. ê° ë‹¨ì–´ë¥¼ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ì¸ì½”ë”© & íŒ¨ë”© <br><br>\n",
    "\n",
    "ìœ„ì—ì„œ tensorflow_datasetsì˜ SubwordTextEncoderë¥¼ ì‚¬ìš©í•´ì„œ tokenizerë¥¼ ì •ì˜í•˜ê³  Vocabularyë¥¼ ìƒì„±í•˜ì˜€ìœ¼ë¯€ë¡œ <br><br>\n",
    "\n",
    "tokenizer.encode()ë¡œ ê° ë‹¨ì–´ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜í•  ìˆ˜ ìˆê³ , ë˜ëŠ”, <br>\n",
    "tokenizer.decode()ë¥¼ í†µí•´ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ! <br><br>\n",
    "\n",
    "22ë²ˆì§¸ ìƒ˜í”Œì„ tokenizer.encode()ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•´ì„œ ë³€í™˜ ê²°ê³¼ í™•ì¸\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ê°€ìŠ¤ë¹„ ì¥ë‚œ ì•„ë‹˜\në‹¤ìŒ ë‹¬ì—ëŠ” ë” ì ˆì•½í•´ë´ìš”.\n"
     ]
    }
   ],
   "source": [
    "# 22ë²ˆì§¸ ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "\n",
    "print(inputs[21])\n",
    "print(outputs[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì •ìˆ˜ ì¸ì½”ë”© í›„ì˜ 21ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: [5739, 607, 2483, 4145]\nì •ìˆ˜ ì¸ì½”ë”© í›„ì˜ 21ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: [2351, 7484, 5, 6250, 94, 7923]\n"
     ]
    }
   ],
   "source": [
    "# ì„ì˜ì˜ 22ë²ˆì§¸ ìƒ˜í”Œì— ëŒ€í•´ì„œ ì •ìˆ˜ ì¸ì½”ë”© ì‘ì—…ì„ ìˆ˜í–‰.\n",
    "# ê° í† í°ì„ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ë³€í™˜\n",
    "\n",
    "print('ì •ìˆ˜ ì¸ì½”ë”© í›„ì˜ 21ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: {}'.format(tokenizer.encode(inputs[21])))\n",
    "print('ì •ìˆ˜ ì¸ì½”ë”© í›„ì˜ 21ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: {}'.format(tokenizer.encode(outputs[21])))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜ê°€ ë¶€ì—¬ëœ Vocabularyë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ì‹œí€€ìŠ¤ê°€ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ì¸ì½”ë”©ëœ ê²°ê³¼ë¥¼ í™•ì¸ ê°€ëŠ¥ <br>\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ ì…‹ì— ëŒ€í•´ì„œ ì „ë¶€ ì •ìˆ˜ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•œ ë’¤, ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì •í•˜ê³  í•´ë‹¹ ê¸¸ì´ë¡œ íŒ¨ë”©(padding)\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# ìƒ˜í”Œì˜ ìµœëŒ€ í—ˆìš© ê¸¸ì´ ë˜ëŠ” íŒ¨ë”© í›„ì˜ ìµœì¢… ê¸¸ì´\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ìˆ˜ ì¸ì½”ë”©, ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ëŠ” ìƒ˜í”Œ ì œê±°, íŒ¨ë”©\n",
    "\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ì¶”ê°€\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # ìµœëŒ€ ê¸¸ì´ 40 ì´í•˜ì¸ ê²½ìš°ì—ë§Œ ë°ì´í„°ì…‹ìœ¼ë¡œ í—ˆìš©\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # ìµœëŒ€ ê¸¸ì´ 40ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ì…‹ì„ íŒ¨ë”©\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì„ ìˆ˜í–‰í•˜ë©´ì„œ ìƒ˜í”Œì˜ ê¸¸ì´ê°€ 40ì„ ë„˜ëŠ” ê²½ìš°ëŠ” ìƒ˜í”Œë“¤ì„ í•„í„°ë§í•˜ì˜€ìœ¼ë¯€ë¡œ ì¼ë¶€ ìƒ˜í”Œì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. <br>\n",
    "ë‹¨ì–´ì¥ì˜ í¬ê¸°ì™€ ìƒ˜í”Œì˜ ê°œìˆ˜ë¥¼ í™•ì¸ !\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ë‹¨ì–´ì¥ì˜ í¬ê¸° : 8135\ní•„í„°ë§ í›„ì˜ ì§ˆë¬¸ ìƒ˜í”Œ ê°œìˆ˜: 11823\ní•„í„°ë§ í›„ì˜ ë‹µë³€ ìƒ˜í”Œ ê°œìˆ˜: 11823\n"
     ]
    }
   ],
   "source": [
    "# ì •ìˆ˜ ì¸ì½”ë”©, íŒ¨ë”© ê³¼ì •ì—ì„œ ì¼ë¶€ ìƒ˜í”Œ ì œì™¸ í›„ ë‹¨ì–´ì¥ í¬ê¸° ë° ìƒ˜í”Œ ê°œìˆ˜ í™•ì¸\n",
    "\n",
    "inputs, outputs = tokenize_and_filter(inputs, outputs)\n",
    "print('ë‹¨ì–´ì¥ì˜ í¬ê¸° :',(VOCAB_SIZE))\n",
    "print('í•„í„°ë§ í›„ì˜ ì§ˆë¬¸ ìƒ˜í”Œ ê°œìˆ˜: {}'.format(len(inputs)))\n",
    "print('í•„í„°ë§ í›„ì˜ ë‹µë³€ ìƒ˜í”Œ ê°œìˆ˜: {}'.format(len(outputs)))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ë°ì´í„°ì…‹ ì¤€ë¹„ <br><br>\n",
    "\n",
    "ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ìŒì„ tf.data.Dataset API ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„± <br><br><br>\n",
    "\n",
    "\n",
    "### êµì‚¬ ê°•ìš” (Teacher Forcing) ì ìš© <br><br>\n",
    "\n",
    "ì´ë•Œ, êµì‚¬ ê°•ìš”ë¥¼ ìœ„í•´ì„œ <br>\n",
    "```answers[:, :-1]``` ë¥¼ ë””ì½”ë”ì˜ ì…ë ¥ê°’, ```answers[:, 1:]``` ë¥¼ ë””ì½”ë”ì˜ ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° íŒŒì´í”„ë¼ì¸ (í•™ìŠµ ë°ì´í„°ì…‹) êµ¬ì„±\n",
    "# ë°ì´í„°ì…‹ êµ¬ì„±ì‹œ êµì‚¬ ê°•ìš” ì ìš©\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# ë””ì½”ë”ëŠ” ì´ì „ì˜ targetì„ ë‹¤ìŒì˜ inputìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "# ì´ì— ë”°ë¼ outputsì—ì„œëŠ” START_TOKENì„ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': inputs,\n",
    "        'dec_inputs': outputs[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': outputs[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì— í•„ìš”í•œ í•¨ìˆ˜ë“¤ ì‘ì„± <br><br>\n",
    "\n",
    "- Positional Encoding Layer (í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´) <br><br>\n",
    "\n",
    "\n",
    "- Scaled Dot-product Attention (í”„ë¡œë•íŠ¸ ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜) <br>\n",
    "- Multi-head Attention (ë©€í‹°-í—¤ë“œ ì–´í…ì…˜) <br><br>\n",
    "\n",
    "\n",
    "- Padding Mask (íŒ¨ë”© ë§ˆìŠ¤í¬) <br>\n",
    "- Look-ahead Mask (ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬) <br><br>\n",
    "\n",
    "\n",
    "- Encoder (ì¸ì½”ë”) <br>\n",
    "- Decoder (ë””ì½”ë”) <br>\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### í¬ì§€ì…”ë„ ì¸ì½”ë”© (Positional Encoding) <br><br>\n",
    "\n",
    "ì„ë² ë”© ë¬¸ì¥ í–‰ë ¬ì— í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ í•´ì£¼ì—ˆì„ ë•Œ, <br>\n",
    "ê°™ì€ ë‹¨ì–´ë¼ê³  í•˜ë”ë¼ë„ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ í•´ì¤€ ê²½ìš°ì—ëŠ” ì„ë² ë”© ë²¡í„°ê°’ì´ ë‹¬ë¼ì§€ë¯€ë¡œ, <br>\n",
    "ê°™ì€ ë‹¨ì–´ë¼ê³  í•´ë„ ê°ê° ë‹¤ë¥¸ ìœ„ì¹˜ì— ë“±ì¥í–ˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ëª¨ë¸ì— ì•Œë ¤ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br><br>\n",
    "\n",
    "\n",
    "### í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´ <br>\n",
    "ì¸ì½”ë”ì™€ ë””ì½”ë” í•¨ìˆ˜ì— ë“¤ì–´ê°€ê¸° ìœ„í•œ í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´ í•¨ìˆ˜ë¥¼ ì‘ì„±\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´ ì‘ì„±\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # ë°°ì—´ì˜ ì§ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” sin í•¨ìˆ˜ ì ìš©\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # ë°°ì—´ì˜ í™€ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” cosine í•¨ìˆ˜ ì ìš©\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### Scaled Dot-product Attention <br>\n",
    "\n",
    "Multi-head Attention (ë©€í‹°-í—¤ë“œ ì–´í…ì…˜) í•¨ìˆ˜ì— ë“¤ì–´ê°€ê¸° ìœ„í•œ ìŠ¤ì¼€ì¼ë“œ ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ <br><br>\n",
    "\n",
    "ì¸ì½”ë” Layer ì™€ ë””ì½”ë” Layer ì— ë“¤ì–´ê°€ê¸° ìœ„í•œ ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ í•¨ìˆ˜ ì‘ì„± <br>\n",
    "ë‚´ë¶€ì ìœ¼ë¡œ Scaled Dot-product Attention í•¨ìˆ˜ í˜¸ì¶œ\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©€í‹°-í—¤ë“œ ì–´í…ì…˜ êµ¬í˜„\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # ë³‘ë ¬ ì—°ì‚°ì„ ìœ„í•œ ë¨¸ë¦¬ë¥¼ ì—¬ëŸ¬ ê°œ ë§Œë“­ë‹ˆë‹¤.\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # ì–´í…ì…˜ ì—°ì‚° í›„ì— ê° ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì—°ê²°(concatenate)í•©ë‹ˆë‹¤.\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### íŒ¨ë”© ë§ˆìŠ¤í¬ <br><br>\n",
    "\n",
    "ì´ í•¨ìˆ˜ì— ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ í•˜ë©´, <br>\n",
    "ì´ í•¨ìˆ˜ëŠ” ìˆ«ìê°€ 0ì¸ ë¶€ë¶„ì„ ì²´í¬í•œ ë²¡í„°ë¥¼ ë¦¬í„´ <br><br>\n",
    "\n",
    "\n",
    "#### íŒ¨ë”© ë§ˆìŠ¤í¬ í•¨ìˆ˜ êµ¬í˜„ <br>\n",
    "í•™ìŠµì„ ìœ„í•œ ëª¨ë¸ ì •ì˜í•  ë•Œ, tf.keras.layers.Lambda() ì˜ ì¸ìë¡œ ë“¤ì–´ê°„ ë’¤, <br>\n",
    "ìµœì¢…ì ìœ¼ë¡œ ì¸ì½”ë”, ë””ì½”ë” í•¨ìˆ˜ì˜ ì¸ìë¡œ ë“¤ì–´ê°ˆ íŒ¨ë”© ë§ˆìŠ¤í¬ í•¨ìˆ˜ ì‘ì„± <br>\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨ë”© ë§ˆìŠ¤í‚¹ êµ¬í˜„\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[[[0. 0. 1. 0. 1.]]]\n\n\n [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬ <br><br>\n",
    "\n",
    "Query ë‹¨ì–´ ë’¤ì— ë‚˜ì˜¤ëŠ” Key ë‹¨ì–´ë“¤ì— ëŒ€í•´ì„œëŠ” ë§ˆìŠ¤í‚¹í•˜ì—¬ ìˆ«ì 0 ì¶œë ¥ (?) <br><br>\n",
    "\n",
    "\n",
    "#### ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬ í•¨ìˆ˜ êµ¬í˜„ <br>\n",
    "\n",
    "í•™ìŠµì„ ìœ„í•œ ëª¨ë¸ ì •ì˜í•  ë•Œ, tf.keras.layers.Lambda() ì˜ ì¸ìë¡œ ë“¤ì–´ê°„ ë’¤, <br>\n",
    "ìµœì¢…ì ìœ¼ë¡œ ì¸ì½”ë”, ë””ì½”ë” í•¨ìˆ˜ì˜ ì¸ìë¡œ ë“¤ì–´ê°ˆ íŒ¨ë”© ë§ˆìŠ¤í¬ í•¨ìˆ˜ ì‘ì„± <br><br>\n",
    "\n",
    "\n",
    "ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í‚¹ê³¼ íŒ¨ë”© ë§ˆìŠ¤í‚¹ì€ ë³„ê°œì´ë¯€ë¡œ, <br>\n",
    "ì´ ë§ˆìŠ¤í‚¹ì„ ìˆ˜í–‰í•  ë•Œ ë§Œì•½ì— ìˆ«ì 0ì¸ ë‹¨ì–´ê°€ ìˆë‹¤ë©´ ì´ ë˜í•œ íŒ¨ë”© í•´ì•¼ í•©ë‹ˆë‹¤. <br>\n",
    "ê·¸ë˜ì„œ create_look_ahead_mask() í•¨ìˆ˜ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì•ì„œ êµ¬í˜„í•œ íŒ¨ë”© ë§ˆìŠ¤í¬ í•¨ìˆ˜ë„ í˜¸ì¶œ.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬ êµ¬í˜„\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[[[0. 1. 1. 1. 1.]\n   [0. 0. 1. 1. 1.]\n   [0. 0. 0. 1. 1.]\n   [0. 0. 0. 0. 1.]\n   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[[[1. 1. 1. 1. 1.]\n   [1. 0. 1. 1. 1.]\n   [1. 0. 0. 1. 1.]\n   [1. 0. 0. 0. 1.]\n   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ìˆ«ì 0ì´ í¬í•¨ë˜ì—ˆì„ ê²½ìš°ë„ í…ŒìŠ¤íŠ¸\n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ì¸ì½”ë” Layer <br><br>\n",
    "\n",
    "í•˜ë‚˜ì˜ ì¸ì½”ë” ì¸µì€ í¬ê²Œ ì´ 2ê°œì˜ ì„œë¸Œ ì¸µ(sublayer)ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì§‘ë‹ˆë‹¤. <br>\n",
    "ë°”ë¡œ __ì…€í”„ ì–´í…ì…˜__ê³¼ __í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§__ì…ë‹ˆë‹¤. <br>\n",
    "ì…€í”„ ì–´í…ì…˜ì€ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ìœ¼ë¡œ ë³‘ë ¬ì ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. <br><br>\n",
    "\n",
    "\n",
    "#### ì¸ì½”ë” Layer í•¨ìˆ˜ë¡œ êµ¬í˜„ <br><br>\n",
    "\n",
    "ë‘ ê°œì˜ ì„œë¸Œ ì¸µì„ ê°€ì§€ëŠ” í•˜ë‚˜ì˜ ì¸ì½”ë” ì¸µì„ êµ¬í˜„í•˜ëŠ” í•¨ìˆ˜ <br>\n",
    "í•¨ìˆ˜ ë‚´ë¶€ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì„œë¸Œ ì¸µì™€ ë‘ ë²ˆì§¸ ì„œë¸Œ ì¸µì„ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ì½”ë” í•˜ë‚˜ì˜ ë ˆì´ì–´ë¥¼ í•¨ìˆ˜ë¡œ êµ¬í˜„.\n",
    "# ì´ í•˜ë‚˜ì˜ ë ˆì´ì–´ ì•ˆì—ëŠ” ë‘ ê°œì˜ ì„œë¸Œ ë ˆì´ì–´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "\t# íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # ì²« ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì…€í”„ ì–´í…ì…˜)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ” Dropoutê³¼ Layer Normalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : 2ê°œì˜ ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µì˜ ê²°ê³¼ëŠ” Dropoutê³¼ LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ì¸ì½”ë” <br><br>\n",
    "\n",
    "\n",
    "#### ì¸ì½”ë” Layerë¥¼ ìŒ“ì•„ ì¸ì½”ë” ë§Œë“¤ê¸° <br>\n",
    "êµ¬í˜„í•œ ì¸ì½”ë” ì¸µì„ ì„ë² ë”© ì¸µ(Embedding layer)ê³¼ í¬ì§€ì…”ë„ ì¸ì½”ë”©(Positional Encoding)ì„ ì—°ê²°í•˜ê³ , <br>\n",
    "ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë§Œí¼ ì¸ì½”ë” ì¸µì„ ìŒ“ìŒìœ¼ë¡œì¨ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ê°€ ì™„ì„± ! <br><br><br>\n",
    "\n",
    "\n",
    "#### Normalize <br>\n",
    "ì¸ì½”ë”ì™€ ë””ì½”ë” ë‚´ë¶€ì—ì„œëŠ” ê° ì„œë¸Œì¸µ ì´í›„ì— í›ˆë ¨ì„ ë•ëŠ” Layer Normalizationì´ë¼ëŠ” í…Œí¬ë‹‰ì´ ì‚¬ìš© <br>\n",
    "\n",
    "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ num_layers ê°œìˆ˜ì˜ ì¸ì½”ë” ì¸µì„ ìŒ“ìŠµë‹ˆë‹¤. <br>\n",
    "( ë…¼ë¬¸ì—ì„œëŠ” ì´ 6ê°œì˜ ì¸ì½”ë” ì¸µì„ ì‚¬ìš© , ì‹¤ìŠµì—ì„œëŠ” ì‹œê°„ìƒ ì ê²Œ )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ì½”ë” ë§Œë“¤ê¸° (ì¸ì½”ë” ë ˆì´ì–´ ìŒ“ê¸°)\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "\t# íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # ì„ë² ë”© ë ˆì´ì–´\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # í¬ì§€ì…”ë„ ì¸ì½”ë”©\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layersë§Œí¼ ìŒ“ì•„ì˜¬ë¦° ì¸ì½”ë”ì˜ ì¸µ.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ë””ì½”ë” Layer <br><br>\n",
    "\n",
    "ì²« ë²ˆì§¸ëŠ” ì…€í”„ ì–´í…ì…˜, ë‘ ë²ˆì§¸ëŠ” ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜, ì„¸ ë²ˆì§¸ëŠ” í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ì…ë‹ˆë‹¤. ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ì€ ì…€í”„ ì–´í…ì…˜ê³¼ëŠ” ë‹¬ë¦¬, Queryê°€ ë””ì½”ë”ì˜ ë²¡í„°ì¸ ë°˜ë©´ì— Keyì™€ Valueê°€ ì¸ì½”ë”ì˜ ë²¡í„°ë¼ëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤. ì´ ë¶€ë¶„ì´ ì¸ì½”ë”ê°€ ì…ë ¥ ë¬¸ì¥ìœ¼ë¡œë¶€í„° ì •ë³´ë¥¼ ë””ì½”ë”ì— ì „ë‹¬í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. <br><br>\n",
    "\n",
    "ì¸ì½”ë”ì˜ ì…€í”„ ì–´í…ì…˜ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë””ì½”ë”ì˜ ì…€í”„ ì–´í…ì…˜, ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ ë‘ ê°œì˜ ì–´í…ì…˜ ëª¨ë‘ ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ì„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ìœ¼ë¡œ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "#### ë””ì½”ë” Layer í•¨ìˆ˜ë¡œ êµ¬í˜„ <br>\n",
    "\n",
    "ë””ì½”ë”ì˜ ì„¸ ê°œì˜ ì„œë¸Œ ì¸µì„ ë‚´ë¶€ì ìœ¼ë¡œ êµ¬í˜„\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë””ì½”ë” í•˜ë‚˜ì˜ ë ˆì´ì–´ë¥¼ í•¨ìˆ˜ë¡œ êµ¬í˜„.\n",
    "# ì´ í•˜ë‚˜ì˜ ë ˆì´ì–´ ì•ˆì—ëŠ” ì„¸ ê°œì˜ ì„œë¸Œ ë ˆì´ì–´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # ì²« ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì…€í”„ ì–´í…ì…˜)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ” LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë§ˆìŠ¤í¬ë“œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # ë§ˆìŠ¤í¬ë“œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ”\n",
    "  # Dropoutê³¼ LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # ì„¸ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : 2ê°œì˜ ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µì˜ ê²°ê³¼ëŠ” Dropoutê³¼ LayerNormalization ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ë””ì½”ë” <br><br>\n",
    "\n",
    "\n",
    "#### ë””ì½”ë” Layer ìŒ“ì•„ ë””ì½”ë” ë§Œë“¤ê¸° <br>\n",
    "\n",
    "ë””ì½”ë”ì˜ ì¸µì€ ì„ë² ë”© ì¸µ(Embedding layer)ê³¼ í¬ì§€ì…”ë„ ì¸ì½”ë”©(Positional Encoding)ì„ ì—°ê²°í•˜ê³ , <br>\n",
    "ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë§Œí¼ ë””ì½”ë” ì¸µì„ ìŒ“ì•„ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë”ê°€ ì™„ì„± <br><br>\n",
    "\n",
    "ì¸ì½”ë”ì™€ ë§ˆì°¬ê°€ì§€ë¡œ num_layers ê°œìˆ˜ì˜ ë””ì½”ë” ì¸µì„ ìŒ“ìŠµë‹ˆë‹¤. <br>\n",
    "( ë…¼ë¬¸ì—ì„œëŠ” ì´ 6ê°œì˜ ë””ì½”ë” ì¸µì„ ì‚¬ìš©, í•™ìŠµì—ì„œëŠ” ì‹œê°„ìƒ ë” ì ê²Œ )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë””ì½”ë” ë§Œë“¤ê¸° (ë””ì½”ë” ë ˆì´ì–´ ìŒ“ê¸°)\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "\t# íŒ¨ë”© ë§ˆìŠ¤í¬\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "\t# ì„ë² ë”© ë ˆì´ì–´# ë””ì½”ë” ë§Œë“¤ê¸° (ë””ì½”ë” ë ˆì´ì–´ ìŒ“ê¸°)\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "\t# íŒ¨ë”© ë§ˆìŠ¤í¬\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "\t# ì„ë² ë”© ë ˆì´ì–´\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "\t# í¬ì§€ì…”ë„ ì¸ì½”ë”©\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "\t# Dropoutì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "ì¸ì½”ë” ì¸µê³¼ ë””ì½”ë” ì¸µì„ ê°ê° í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤. <br>\n",
    "ì´ë¥¼ í•˜ë‚˜ë¡œ ì¡°í•©í•˜ì—¬ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ëª¨ë¸ ì •ì˜ ë° í•™ìŠµí•˜ê¸° <br><br>\n",
    "\n",
    "ì•ì„œ ì‚¬ìš©í•œ ì¸ì½”ë” ì¸µ í•¨ìˆ˜ì™€ ë””ì½”ë” ì¸µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ëœìŠ¤í¬ë¨¸ í•¨ìˆ˜ë¥¼ ì •ì˜\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¸ëœìŠ¤í¬ë¨¸ í•¨ìˆ˜ë¥¼ ì •ì˜\n",
    "# ì•ì„œ ì‚¬ìš©í•œ ì¸ì½”ë” ì¸µ í•¨ìˆ˜ì™€ ë””ì½”ë” ì¸µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# ì¸ì½”ë”ì—ì„œ íŒ¨ë”©ì„ ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # ë””ì½”ë”ì—ì„œ ë¯¸ë˜ì˜ í† í°ì„ ë§ˆìŠ¤í¬ í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "  # ë‚´ë¶€ì ìœ¼ë¡œ íŒ¨ë”© ë§ˆìŠ¤í¬ë„ í¬í•¨ë˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì–´í…ì…˜ ë¸”ë¡ì—ì„œ ì¸ì½”ë”ì˜ ë²¡í„°ë“¤ì„ ë§ˆìŠ¤í‚¹\n",
    "  # ë””ì½”ë”ì—ì„œ íŒ¨ë”©ì„ ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # ì¸ì½”ë”\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # ë””ì½”ë”\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 1. ëª¨ë¸ ìƒì„± <br><br>\n",
    "\n",
    "num_layers, d-Model, unitsëŠ” ì „ë¶€ ì‚¬ìš©ìê°€ ì •í•  ìˆ˜ ìˆëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°’ <br><br>\n",
    "\n",
    "\n",
    "ë…¼ë¬¸ì—ì„œ num_layers=6, d-Model=512ì˜€ì§€ë§Œ, <br>\n",
    "ë¹ ë¥´ê³  ì›í™œí•œ í›ˆë ¨ì„ ìœ„í•´ ì—¬ê¸°ì„œëŠ” ê° í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë…¼ë¬¸ë³´ë‹¤ëŠ” ì‘ì€ ê°’ì„ ì‚¬ìš©\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"transformer\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninputs (InputLayer)             [(None, None)]       0                                            \n__________________________________________________________________________________________________\ndec_inputs (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\nenc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n__________________________________________________________________________________________________\nencoder (Model)                 (None, None, 256)    3136768     inputs[0][0]                     \n                                                                 enc_padding_mask[0][0]           \n__________________________________________________________________________________________________\nlook_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n__________________________________________________________________________________________________\ndec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n__________________________________________________________________________________________________\ndecoder (Model)                 (None, None, 256)    3664128     dec_inputs[0][0]                 \n                                                                 encoder[1][0]                    \n                                                                 look_ahead_mask[0][0]            \n                                                                 dec_padding_mask[0][0]           \n__________________________________________________________________________________________________\noutputs (Dense)                 (None, None, 8135)   2090695     decoder[1][0]                    \n==================================================================================================\nTotal params: 8,891,591\nTrainable params: 8,891,591\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "NUM_LAYERS = 2 # ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì¸µì˜ ê°œìˆ˜\n",
    "D_MODEL = 256 # ì¸ì½”ë”ì™€ ë””ì½”ë” ë‚´ë¶€ì˜ ì…, ì¶œë ¥ì˜ ê³ ì • ì°¨ì›\n",
    "NUM_HEADS = 8 # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì—ì„œì˜ í—¤ë“œ ìˆ˜ \n",
    "UNITS = 512 # í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ì˜ ì€ë‹‰ì¸µì˜ í¬ê¸°\n",
    "DROPOUT = 0.1 # ë“œë¡­ì•„ì›ƒì˜ ë¹„ìœ¨\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 2. ì†ì‹¤ í•¨ìˆ˜ (Loss function) ì‘ì„± <br><br>\n",
    "\n",
    "ë ˆì´ë¸”ì¸ ì‹œí€€ìŠ¤ì— íŒ¨ë”©ì´ ë˜ì–´ì ¸ ìˆìœ¼ë¯€ë¡œ, <br>\n",
    "Lossë¥¼ ê³„ì‚°í•  ë•Œ íŒ¨ë”© ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ì‹¤í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 3. ì»¤ìŠ¤í…€ í•™ìŠµë¥  (Learning rate) <br><br>\n",
    "\n",
    "#### Learning rate Scheduling <br>\n",
    "ë”¥ëŸ¬ë‹ ëª¨ë¸í•™ìŠµ ì‹œ learning rateëŠ” ë§¤ìš° ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ëª¨ë¸í•™ìŠµ ì´ˆê¸°ì— learning rateë¥¼ ê¸‰ê²©íˆ ë†’ì˜€ë‹¤ê°€, ì´í›„ train stepì´ ì§„í–‰ë¨ì— ë”°ë¼ ì„œì„œíˆ ë‚®ì¶”ì–´ ê°€ë©´ì„œ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ê²Œ í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•ì„ ë„ë¦¬ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ë°©ë²•ì„ ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§(Custom Learning rate Scheduling)ì´ë¼ê³  í•©ë‹ˆë‹¤. <br><br>\n",
    "\n",
    "ë…¼ë¬¸ì— ë‚˜ì˜¨ ê³µì‹ì„ ì°¸ê³ í•˜ì—¬ ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•œ ì•„ë‹´ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. <br>\n",
    "ë…¼ë¬¸ì— ë‚˜ì˜¨ ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. <br><br>\n",
    "\n",
    "$lr \\quad = \\quad d_{model}^{-0.5} * \\min(step\\_num^{-0.5} \\; , \\; step\\_num * warmup\\_steps^{-1.5})$\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¤ìŠ¤í…€ learning rate ìŠ¤ì¼€ì¤„ë§ì„ ìœ„í•œ í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ì‹œê°í™” <br>\n",
    "\n",
    "ì •ì˜í•œ ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ê³„íšì„ ì‹œê°í™”í•´ ë´…ì‹œë‹¤. ìœ„ì— ì–¸ê¸‰í•œ ìˆ˜ì‹ì€ step_numâˆ’0.5ì— ë¹„ë¡€í•˜ëŠ” ë¶€ë¶„ê³¼ step_numì— ë¹„ë¡€í•˜ëŠ” ë¶€ë¶„ ì¤‘ ì‘ì€ ìª½ì„ íƒí•˜ë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í•™ìŠµ ì´ˆê¸°ì—ëŠ” learning_rateê°€ step_numì— ë¹„ë¡€í•´ì„œ ì¦ê°€í•˜ë‹¤ê°€ ì´í›„ë¡œëŠ” ê°ì†Œí•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "metadata": {},
     "execution_count": 206
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 408.73959 262.19625\" width=\"408.73959pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-09T21:03:25.653204</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 408.73959 262.19625 \nL 408.73959 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 62.86875 224.64 \nL 397.66875 224.64 \nL 397.66875 7.2 \nL 62.86875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3d3e064ab8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.086932\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(74.905682 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.132577\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25000 -->\n      <g transform=\"translate(100.226327 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"154.178221\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50000 -->\n      <g transform=\"translate(138.271971 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.223866\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75000 -->\n      <g transform=\"translate(176.317616 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.269511\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100000 -->\n      <g transform=\"translate(211.182011 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.315156\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125000 -->\n      <g transform=\"translate(249.227656 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.3608\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150000 -->\n      <g transform=\"translate(287.2733 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.406445\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175000 -->\n      <g transform=\"translate(325.318945 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"382.45209\" xlink:href=\"#m3d3e064ab8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200000 -->\n      <g transform=\"translate(363.36459 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Train Step -->\n     <g transform=\"translate(205.300781 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"239.888672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"271.675781\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"335.152344\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"374.361328\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"435.884766\" xlink:href=\"#DejaVuSans-112\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma5d708a4d5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0000 -->\n      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"186.467744\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.0002 -->\n      <g transform=\"translate(20.878125 190.266963)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"158.179125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.0004 -->\n      <g transform=\"translate(20.878125 161.978344)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"129.890506\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.0006 -->\n      <g transform=\"translate(20.878125 133.689725)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"101.601887\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.0008 -->\n      <g transform=\"translate(20.878125 105.401105)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"73.313267\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.0010 -->\n      <g transform=\"translate(20.878125 77.112486)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"45.024648\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.0012 -->\n      <g transform=\"translate(20.878125 48.823867)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#ma5d708a4d5\" y=\"16.736029\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.0014 -->\n      <g transform=\"translate(20.878125 20.535248)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- Learning Rate -->\n     <g transform=\"translate(14.798438 150.679375)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n       <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n       <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"115.486328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"176.765625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"216.128906\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"279.507812\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"307.291016\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"370.669922\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"434.146484\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"465.933594\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"533.166016\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"594.445312\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"633.654297\" xlink:href=\"#DejaVuSans-101\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p6afdf3baea)\" d=\"M 78.086932 214.756364 \nL 84.174235 17.083636 \nL 84.247283 18.259105 \nL 85.266906 32.745294 \nL 86.359577 45.191047 \nL 87.532905 56.071364 \nL 88.785367 65.648995 \nL 90.113921 74.125453 \nL 91.510957 81.644158 \nL 92.993215 88.43566 \nL 94.578958 94.662118 \nL 96.269706 100.381872 \nL 98.024372 105.530736 \nL 99.871868 110.264826 \nL 101.784803 114.570937 \nL 103.854486 118.678655 \nL 106.038306 122.508219 \nL 108.311914 126.045624 \nL 110.734661 129.400626 \nL 113.341548 132.617024 \nL 116.0854 135.638199 \nL 118.887081 138.402971 \nL 121.944429 141.112368 \nL 125.061129 143.597414 \nL 128.559806 146.107998 \nL 132.375023 148.564146 \nL 136.318074 150.844489 \nL 140.866811 153.203396 \nL 145.662084 155.427543 \nL 150.597365 157.482168 \nL 155.827881 159.442459 \nL 161.671692 161.411118 \nL 167.749864 163.250962 \nL 175.024191 165.221169 \nL 183.243572 167.196468 \nL 191.569481 168.974371 \nL 200.639563 170.70109 \nL 211.750413 172.57187 \nL 224.00872 174.382606 \nL 237.329261 176.108102 \nL 254.314358 178.017775 \nL 272.720841 179.79809 \nL 292.273259 181.431888 \nL 318.027117 183.27107 \nL 344.267959 184.863282 \nL 374.53403 186.430336 \nL 382.450568 186.801147 \nL 382.450568 186.801147 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 62.86875 224.64 \nL 62.86875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 397.66875 224.64 \nL 397.66875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 62.86875 224.64 \nL 397.66875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 62.86875 7.2 \nL 397.66875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6afdf3baea\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"62.86875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ì‹œê°í™”\n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 4. ëª¨ë¸ ì»´íŒŒì¼ <br><br>\n",
    "\n",
    "ì†ì‹¤ í•¨ìˆ˜ (Loss function) ì™€ ì»¤ìŠ¤í…€ ëœ í•™ìŠµë¥  (learning rate) ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì»´íŒŒì¼\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì»´íŒŒì¼\n",
    "# ì†ì‹¤í•¨ìˆ˜, ì»¤ìŠ¤í…€ í•™ìŠµë¥  ì‚¬ìš©\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### 5. ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "20 EPOCHS í•™ìŠµ\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 1.4555 - accuracy: 0.0241\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 1.1776 - accuracy: 0.0494\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 1.0026 - accuracy: 0.0508\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.9281 - accuracy: 0.0543\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 0.8694 - accuracy: 0.0576\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 14s 75ms/step - loss: 0.8094 - accuracy: 0.0618\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 14s 76ms/step - loss: 0.7434 - accuracy: 0.0677\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 0.6705 - accuracy: 0.0754\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 14s 73ms/step - loss: 0.5915 - accuracy: 0.0840\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 0.5098 - accuracy: 0.0934\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 0.4274 - accuracy: 0.1039\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 0.3475 - accuracy: 0.1146\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.2732 - accuracy: 0.1254\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 0.2071 - accuracy: 0.1356\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 14s 73ms/step - loss: 0.1524 - accuracy: 0.1451\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 0.1103 - accuracy: 0.1529\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 13s 73ms/step - loss: 0.0810 - accuracy: 0.1582\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 13s 73ms/step - loss: 0.0612 - accuracy: 0.1619\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.0511 - accuracy: 0.1635\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.0458 - accuracy: 0.1642\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb815b76850>"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ì±—ë´‡ í…ŒìŠ¤íŠ¸ <br><br>\n",
    "\n",
    "ì˜ˆì¸¡(inference) ë‹¨ê³„ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. <br><br>\n",
    "\n",
    "1. ìƒˆë¡œìš´ ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•´ì„œëŠ” í›ˆë ¨ ë•Œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ë¥¼ ê±°ì¹œë‹¤. <br>\n",
    "2. ì…ë ¥ ë¬¸ì¥ì„ í† í¬ë‚˜ì´ì§•í•˜ê³ , START_TOKENê³¼ END_TOKENì„ ì¶”ê°€í•œë‹¤. <br>\n",
    "3. íŒ¨ë”© ë§ˆìŠ¤í‚¹ê³¼ ë£© ì–´í—¤ë“œ ë§ˆìŠ¤í‚¹ì„ ê³„ì‚°í•œë‹¤. <br>\n",
    "4. ë””ì½”ë”ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ë¡œë¶€í„° ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤. <br>\n",
    "5. ë””ì½”ë”ëŠ” ì˜ˆì¸¡ëœ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ê¸°ì¡´ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ì— ì¶”ê°€í•˜ì—¬ ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. <br>\n",
    "6. END_TOKENì´ ì˜ˆì¸¡ë˜ê±°ë‚˜ ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ì— ë„ë‹¬í•˜ë©´ ë””ì½”ë”ëŠ” ë™ì‘ì„ ë©ˆì¶˜ë‹¤. <br> <br>\n",
    "\n",
    "ìœ„ì˜ ê³¼ì •ì„ ëª¨ë‘ ë‹´ì€ decoder_inference() í•¨ìˆ˜ë¥¼ ì‘ì„±\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ì„ ìœ„í•œ decoder_inference() í•¨ìˆ˜ë¥¼ ì‘ì„±\n",
    "\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # ì…ë ¥ëœ ë¬¸ì¥ì„ ì •ìˆ˜ ì¸ì½”ë”© í›„, ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ì•ë’¤ë¡œ ì¶”ê°€.\n",
    "  # ex) Where have you been? â†’ [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # ë””ì½”ë”ì˜ í˜„ì¬ê¹Œì§€ì˜ ì˜ˆì¸¡í•œ ì¶œë ¥ ì‹œí€€ìŠ¤ê°€ ì§€ì†ì ìœ¼ë¡œ ì €ì¥ë˜ëŠ” ë³€ìˆ˜.\n",
    "  # ì²˜ìŒì—ëŠ” ì˜ˆì¸¡í•œ ë‚´ìš©ì´ ì—†ìŒìœ¼ë¡œ ì‹œì‘ í† í°ë§Œ ë³„ë„ ì €ì¥. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # ë””ì½”ë”ì˜ ì¸í¼ëŸ°ìŠ¤ ë‹¨ê³„\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # ë””ì½”ë”ëŠ” ìµœëŒ€ MAX_LENGTHì˜ ê¸¸ì´ë§Œí¼ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì„ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # í˜„ì¬ ì˜ˆì¸¡í•œ ë‹¨ì–´ì˜ ì •ìˆ˜\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # ë§Œì•½ í˜„ì¬ ì˜ˆì¸¡í•œ ë‹¨ì–´ê°€ ì¢…ë£Œ í† í°ì´ë¼ë©´ forë¬¸ì„ ì¢…ë£Œ\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # ì˜ˆì¸¡í•œ ë‹¨ì–´ë“¤ì€ ì§€ì†ì ìœ¼ë¡œ output_sequenceì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "    # ì´ output_sequenceëŠ” ë‹¤ì‹œ ë””ì½”ë”ì˜ ì…ë ¥ì´ ë©ë‹ˆë‹¤.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "ì„ì˜ì˜ ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•´ì„œ decoder_inference() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì±—ë´‡ì˜ ëŒ€ë‹µì„ ì–»ëŠ” <br>\n",
    "sentence_generation() í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inference() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¬¸ì¥ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "def sentence_generation(sentence):\n",
    "  # ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë””ì½”ë”ë¥¼ ë™ì‘ ì‹œì¼œ ì˜ˆì¸¡ëœ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë¦¬í„´ë°›ìŠµë‹ˆë‹¤.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('ì…ë ¥ : {}'.format(sentence))\n",
    "  print('ì¶œë ¥ : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### ì±—ë´‡ìœ¼ë¡œ ë¬¸ì¥ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# í…ŒìŠ¤íŠ¸1. ì§ˆë¬¸\n",
    "\n",
    "sentence_generation('ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´?')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 211,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì…ë ¥ : ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´?\nì¶œë ¥ : ì˜ ì§€ë‚´ê³  ìˆì–´ìš”.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ì˜ ì§€ë‚´ê³  ìˆì–´ìš”.'"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ì…ë ¥ : ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„ ë³´ì—¬.\nì¶œë ¥ : ë¨¼ì € ë‹¤ê°€ê°€ ë³´ì„¸ìš”.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ë¨¼ì € ë‹¤ê°€ê°€ ë³´ì„¸ìš”.'"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸2. ë¬¸ì¥\n",
    "\n",
    "sentence_generation('ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„ ë³´ì—¬.')"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## ì´í‰ <br><br>\n",
    "\n",
    "### ì •ê·œí‘œí˜„ì‹ ìˆ˜ì • <br><br>\n",
    "\n",
    "- í•œê¸€ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ì •ê·œí‘œí˜„ì‹ì— ì•ŒíŒŒë²³ì— ì¶”ê°€ë¡œ í•œê¸€ ```ã„±-ã…ê°€-í£``` <br><br>\n",
    "\n",
    "- íŠ¸ëœìŠ¤í¬ë¨¸ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ì€ ë¬¸ì¥ ë‚´ ë‹¨ì–´ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì—, <br>\n",
    "ë¬¸ì¥ì˜ ìœ„ì¹˜ì™€ ë‹¨ì–´ì— ë”°ë¼ êµ¬ë‘ì ì˜ ìœ ì˜í•  ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ì—¬ êµ¬ë‘ì  ì œê±° ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šê³  í•™ìŠµ <br><br>\n",
    "\n",
    "ì •ê·œí‘œí˜„ì‹ì„ ìˆ˜ì • í›„ í•™ìŠµí•œ ê²°ê³¼, <br>\n",
    "êµ¬ë‘ì ì´ ë„ì–´ì ¸ ì¶œë ¥ë˜ëŠ” ë¶€ë¶„ì„ ìˆ˜ì •í•  ìˆ˜ ìˆì—ˆê³ , <br>\n",
    "ë™ì‹œì— ê²°ê³¼ë„ ë§¥ë½ìƒ ë” ìì—°ìŠ¤ëŸ¬ì›€ì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}